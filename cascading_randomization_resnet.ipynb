{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sanity Check (Cascading Randomization) for Saliency Maps: ResNet-18 ImageNet Example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%%capture\n",
    "# do not display output on this cell\n",
    "from torchvision import transforms, models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src import util\n",
    "from captum.attr import IntegratedGradients, Saliency, InputXGradient, GuidedBackprop\n",
    "from src import util\n",
    "import PIL\n",
    "from ntpath import basename\n",
    "import os\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# def show_image(file_path, resize=True, sztple=(299, 299)):\n",
    "#     img = PIL.Image.open(file_path).convert('RGB')\n",
    "#     if resize:\n",
    "#         img = img.resize(sztple, PIL.Image.ANTIALIAS)\n",
    "#     img = np.asarray(img)\n",
    "#     return img\n",
    "\n",
    "def preprocess_image(file_path):\n",
    "    img = PIL.Image.open(file_path).convert('RGB')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = preprocess(img)\n",
    "    return img.unsqueeze(0)\n",
    "\n",
    "def get_image_and_label(file_path, image_net_cls, normalize=False):\n",
    "    img = PIL.Image.open(file_path).convert('RGB')\n",
    "    img_name = basename(file_path)\n",
    "    cls_name = img_name[img_name.find('_') + 1:img_name.find('.')].replace('_', ' ')\n",
    "    label = image_net_cls[cls_name]\n",
    "    if not normalize:\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        img = preprocess(img)\n",
    "        return img, label\n",
    "    else:\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        img = preprocess(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dir_path):\n",
    "        super(MyDataset).__init__()\n",
    "        self.dir_path = dir_path\n",
    "        self.files = [img for img in sorted(os.listdir(dir_path)) if img.endswith(\".JPEG\")]\n",
    "        with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "            self.image_net_cls = {s.strip(): idx for idx, s in enumerate(f.readlines())}\n",
    "        \n",
    "    # def __iter__(self):\n",
    "    #     iter([get_image_and_label(x) for x in os.listdir(self.dir_path)])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        return get_image_and_label(os.path.join(self.dir_path, file_name), self.image_net_cls, normalize=True)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "class MyOriginalImages(MyDataset):\n",
    "    def __init__(self, dir_path):\n",
    "        super().__init__(dir_path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        return get_image_and_label(os.path.join(self.dir_path, file_name), self.image_net_cls, normalize=False)\n",
    "\n",
    "\n",
    "# def show_image(im, title='', ax=None):\n",
    "#     if ax is None:\n",
    "#         plt.figure()\n",
    "#     plt.axis('off')\n",
    "#     im = ((im + 1) * 127.5).astype(np.uint8)\n",
    "#     plt.imshow(im)\n",
    "#     plt.title(title)\n",
    "\n",
    "# img, label = get_image_and_label('imagenet-sample-images/n01440764_tench.JPEG')\n",
    "# plt.imshow(img.squeeze(0).permute(1, 2, 0).numpy())\n",
    "# with open('imagenet-sample-images/n01440764_tench.JPEG', '')\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    cls_index_to_name = {idx: s.strip() for idx, s in enumerate(f.readlines())}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset = MyDataset('imagenet-sample-images')\n",
    "originals = MyOriginalImages('imagenet-sample-images')\n",
    "# full dataset loader\n",
    "# important that batch is 1!\n",
    "# important that shuffle is False!\n",
    "full_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "#samples = [4, 13 ,23] hammerhead, junco, vulture\n",
    "samples = [340, 4, 13, 430, 339] # zebra, hammerhead, junco, basketball, sorrel\n",
    "# samples = np.random.choice(len(dataset), 2, replace=False)\n",
    "dataset_subset = torch.utils.data.Subset(dataset, samples)\n",
    "originals_subset = torch.utils.data.Subset(originals, samples)\n",
    "\n",
    "# important that batch is 1!\n",
    "# important that shuffle is False!\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset_subset, batch_size=1, shuffle=False)\n",
    "originals_loader = torch.utils.data.DataLoader(originals_subset, batch_size=1, shuffle=False)\n",
    "\n",
    "# img, label = get_image_and_label('imagenet-sample-images/n01440764_tench.JPEG', image_net_cls, normalize=True)\n",
    "# with torch.no_grad():\n",
    "#     output = resnet(img)\n",
    "    \n",
    "# probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "# # Read the categories\n",
    "# with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "#     categories = [s.strip() for s in f.readlines()]\n",
    "# # Show top categories per image\n",
    "# top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "# for i in range(top5_prob.size(0)):\n",
    "#     print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "# for img, label in dataset_loader:\n",
    "#     output = resnet(img)\n",
    "#     print(output)\n",
    "#     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# define module paths for cascading randomization\n",
    "module_paths = [\n",
    "    ['fc'],\n",
    "    ['layer4', '1'], ['layer4', '0'],\n",
    "    ['layer3', '1'], ['layer3', '0'],\n",
    "    ['layer2', '1'], ['layer2', '0'],\n",
    "    ['layer1', '1'], ['layer1', '0'],\n",
    "    ['bn1'], ['conv1']\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%matplotlib agg\n",
    "# visualize integrated gradients\n",
    "fig, _ = util.visualize_cascading_randomization(resnet, module_paths, (InputXGradient, False), dataset_loader, originals_loader, cls_index_to_name, viz_method=\"blended_heat_map\")\n",
    "fig.savefig(\"figures/resnet_inputxgradient_cascading_randomization.png\", bbox_inches=\"tight\")"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%matplotlib agg\n",
    "fig, _ = util.visualize_cascading_randomization(resnet, module_paths, (InputXGradient, True), dataset_loader, originals_loader, cls_index_to_name, viz_method=\"blended_heat_map\")\n",
    "fig.savefig(\"figures/resnet_inputxgradient_smoothing_cascading_randomization.png\", bbox_inches=\"tight\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%matplotlib agg\n",
    "# multiple saliency maps for each example\n",
    "for (image, label), (original, _) in zip(dataset_loader, originals_loader):\n",
    "    fig, _ = util.visualize_cascading_randomization2(\n",
    "        resnet,\n",
    "        module_paths,\n",
    "        [(Saliency, False), (Saliency, True), (InputXGradient, False), (InputXGradient, True), (GuidedBackprop, False), (IntegratedGradients, False)],\n",
    "        ['Gradient', 'SmoothGrad', 'Gradient ⊙ Input', 'Gradient ⊙ Input-SG', 'Guided Back-propagation', 'Integrated Gradients'],\n",
    "        (image, label),\n",
    "        original,\n",
    "        viz_method=\"heat_map\"\n",
    "    )\n",
    "    fig.savefig(\"figures/resnet_cascading_randomization.png\", bbox_inches=\"tight\")\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/konrad/miniconda3/envs/sanity_checks_pytorch/lib/python3.9/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:60: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "  warnings.warn(\n",
      "/home/konrad/miniconda3/envs/sanity_checks_pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "dic = util.ssim_saliency_comparison(\n",
    "    resnet,\n",
    "    module_paths,\n",
    "        [(Saliency, False), (Saliency, True), (InputXGradient, False), (InputXGradient, True), (GuidedBackprop, False), (IntegratedGradients, False)],\n",
    "        ['Gradient', 'SmoothGrad', 'Gradient ⊙ Input', 'Gradient ⊙ Input-SG', 'Guided Back-propagation', 'Integrated Gradients'], # integrated gradients takes a fuckton of time\n",
    "    dataset_loader\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "dic"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Gradient': {'fc': 0.7007162118803472,\n",
       "  'layer4_1': 0.5843336223542628,\n",
       "  'layer4_0': 0.586383585026679,\n",
       "  'layer3_1': 0.5460930649541866,\n",
       "  'layer3_0': 0.5469156755935984,\n",
       "  'layer2_1': 0.5016109011083099,\n",
       "  'layer2_0': 0.4848122505316317,\n",
       "  'layer1_1': 0.36857221626667397,\n",
       "  'layer1_0': 0.2829490931925805,\n",
       "  'bn1': 0.3849463556271995,\n",
       "  'conv1': 0.378120144227316},\n",
       " 'SmoothGrad': {'fc': 0.7751769180294782,\n",
       "  'layer4_1': 0.6437133338100526,\n",
       "  'layer4_0': 0.6017864010647115,\n",
       "  'layer3_1': 0.6173261118545617,\n",
       "  'layer3_0': 0.45944497687895786,\n",
       "  'layer2_1': 0.4961996721413362,\n",
       "  'layer2_0': 0.5191355010094192,\n",
       "  'layer1_1': 0.5666334941430149,\n",
       "  'layer1_0': 0.5414745766784212,\n",
       "  'bn1': 0.5908051159945817,\n",
       "  'conv1': 0.52257754807884},\n",
       " 'Gradient ⊙ Input': {'fc': 0.8401561945275986,\n",
       "  'layer4_1': 0.8152612303498616,\n",
       "  'layer4_0': 0.7950904996460721,\n",
       "  'layer3_1': 0.7925661351675649,\n",
       "  'layer3_0': 0.7717537748259116,\n",
       "  'layer2_1': 0.7707802096298083,\n",
       "  'layer2_0': 0.7674233779167575,\n",
       "  'layer1_1': 0.7128512182751209,\n",
       "  'layer1_0': 0.6840297902682121,\n",
       "  'bn1': 0.7283850548879405,\n",
       "  'conv1': 0.7603951003803282},\n",
       " 'Gradient ⊙ Input-SG': {'fc': 0.8311292255907544,\n",
       "  'layer4_1': 0.7524197829522031,\n",
       "  'layer4_0': 0.7703580652193728,\n",
       "  'layer3_1': 0.785623463104131,\n",
       "  'layer3_0': 0.711688735652368,\n",
       "  'layer2_1': 0.7203474528630699,\n",
       "  'layer2_0': 0.7138817597536316,\n",
       "  'layer1_1': 0.7330607859002837,\n",
       "  'layer1_0': 0.7397617561234127,\n",
       "  'bn1': 0.7593378639523966,\n",
       "  'conv1': 0.8024974189896724},\n",
       " 'Guided Back-propagation': {'fc': 0.9957126473489855,\n",
       "  'layer4_1': 0.9865543024170561,\n",
       "  'layer4_0': 0.9784316355330163,\n",
       "  'layer3_1': 0.9458659254292192,\n",
       "  'layer3_0': nan,\n",
       "  'layer2_1': nan,\n",
       "  'layer2_0': 0.9123543135043077,\n",
       "  'layer1_1': 0.9107425256621757,\n",
       "  'layer1_0': 0.8945350856337264,\n",
       "  'bn1': 0.9022605155709392,\n",
       "  'conv1': 0.847975036412616},\n",
       " 'Integrated Gradients': {'fc': 0.821251808523232,\n",
       "  'layer4_1': 0.77318534265305,\n",
       "  'layer4_0': 0.7380110703366103,\n",
       "  'layer3_1': 0.7847893218719931,\n",
       "  'layer3_0': 0.7304766547522321,\n",
       "  'layer2_1': 0.7381688381614527,\n",
       "  'layer2_0': 0.7388835171089185,\n",
       "  'layer1_1': 0.7033683841299212,\n",
       "  'layer1_0': 0.6632571439520911,\n",
       "  'bn1': 0.7144421015161859,\n",
       "  'conv1': 0.7571771516971706}}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "%matplotlib agg\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "ax = fig.subplots()\n",
    "#plot similarities\n",
    "for key, value in dic.items():\n",
    "    ax.plot(\n",
    "        ['original'] + list(value.keys()), [1] + list(value.values()),\n",
    "        label=key,\n",
    "        linestyle='dashed', linewidth=3.5, marker='o', markersize=10\n",
    "    )\n",
    "\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "fig.savefig(\"figures/resnet_ssim_cascading_randomization_2.png\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image = dic[(340, 0)]\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(image, cmap=\"Reds\")\n",
    "print(image)\n",
    "print(image.shape)\n",
    "print(len(dic))\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('sanity_checks_pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "11fbf37fbd24df55005c3b93a6722ff80f8e94e0a7328b0b9ff32e8c2e8e8123"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}