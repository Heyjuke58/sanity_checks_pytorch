{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sanity Check (Cascading Randomization) for Saliency Maps: ResNet-18 ImageNet Example"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%%capture\n",
    "from torchvision import transforms, models\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from src import util\n",
    "from captum.attr import IntegratedGradients, Saliency, InputXGradient, GuidedBackprop\n",
    "from src import util\n",
    "import PIL\n",
    "from ntpath import basename\n",
    "import os\n",
    "\n",
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def preprocess_image(file_path):\n",
    "    img = PIL.Image.open(file_path).convert('RGB')\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    img = preprocess(img)\n",
    "    return img.unsqueeze(0)\n",
    "\n",
    "def get_image_and_label(file_path, image_net_cls, normalize=False):\n",
    "    img = PIL.Image.open(file_path).convert('RGB')\n",
    "    img_name = basename(file_path)\n",
    "    cls_name = img_name[img_name.find('_') + 1:img_name.find('.')].replace('_', ' ')\n",
    "    label = image_net_cls[cls_name]\n",
    "    if not normalize:\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "        img = preprocess(img)\n",
    "        return img, label\n",
    "    else:\n",
    "        preprocess = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ])\n",
    "        img = preprocess(img)\n",
    "        return img, label\n",
    "\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dir_path):\n",
    "        super(MyDataset).__init__()\n",
    "        self.dir_path = dir_path\n",
    "        self.files = [img for img in sorted(os.listdir(dir_path)) if img.endswith(\".JPEG\")]\n",
    "        with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "            self.image_net_cls = {s.strip(): idx for idx, s in enumerate(f.readlines())}\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        return get_image_and_label(os.path.join(self.dir_path, file_name), self.image_net_cls, normalize=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "\n",
    "class MyOriginalImages(MyDataset):\n",
    "    def __init__(self, dir_path):\n",
    "        super().__init__(dir_path)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.files[idx]\n",
    "        return get_image_and_label(os.path.join(self.dir_path, file_name), self.image_net_cls, normalize=False)\n",
    "\n",
    "\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    cls_index_to_name = {idx: s.strip() for idx, s in enumerate(f.readlines())}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "dataset = MyDataset('imagenet-sample-images')\n",
    "originals = MyOriginalImages('imagenet-sample-images')\n",
    "# full dataset loader\n",
    "# important that batch is 1!\n",
    "# important that shuffle is False!\n",
    "full_loader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "#samples = [4, 13 ,23] hammerhead, junco, vulture\n",
    "samples = [340, 4, 13, 430, 339] # zebra, hammerhead, junco, basketball, sorrel\n",
    "# samples = np.random.choice(len(dataset), 2, replace=False)\n",
    "dataset_subset = torch.utils.data.Subset(dataset, samples)\n",
    "originals_subset = torch.utils.data.Subset(originals, samples)\n",
    "\n",
    "# important that batch is 1!\n",
    "# important that shuffle is False!\n",
    "dataset_loader = torch.utils.data.DataLoader(dataset_subset, batch_size=1, shuffle=False)\n",
    "originals_loader = torch.utils.data.DataLoader(originals_subset, batch_size=1, shuffle=False)\n",
    "\n",
    "# img, label = get_image_and_label('imagenet-sample-images/n01440764_tench.JPEG', image_net_cls, normalize=True)\n",
    "# with torch.no_grad():\n",
    "#     output = resnet(img)\n",
    "    \n",
    "# probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "# # Read the categories\n",
    "# with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "#     categories = [s.strip() for s in f.readlines()]\n",
    "# # Show top categories per image\n",
    "# top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "# for i in range(top5_prob.size(0)):\n",
    "#     print(categories[top5_catid[i]], top5_prob[i].item())\n",
    "# for img, label in dataset_loader:\n",
    "#     output = resnet(img)\n",
    "#     print(output)\n",
    "#     break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# define module paths for cascading randomization\n",
    "module_paths = [\n",
    "    ['fc'],\n",
    "    ['layer4', '1'], ['layer4', '0'],\n",
    "    ['layer3', '1'], ['layer3', '0'],\n",
    "    ['layer2', '1'], ['layer2', '0'],\n",
    "    ['layer1', '1'], ['layer1', '0'],\n",
    "    ['bn1'], ['conv1']\n",
    "]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%matplotlib agg\n",
    "# visualize integrated gradients\n",
    "fig, _ = util.visualize_cascading_randomization(resnet, module_paths, (InputXGradient, False), dataset_loader, originals_loader, cls_index_to_name, viz_method=\"blended_heat_map\")\n",
    "fig.savefig(\"figures/resnet-imagenet/inputxgradient_cascrand.png\", bbox_inches=\"tight\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/konrad/miniconda3/envs/sanity_checks_pytorch/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "%matplotlib agg\n",
    "fig, _ = util.visualize_cascading_randomization(resnet, module_paths, (InputXGradient, True), dataset_loader, originals_loader, cls_index_to_name, viz_method=\"blended_heat_map\")\n",
    "fig.savefig(\"figures/resnet-imagenet/inputxgradient_smoothing_cascrand.png\", bbox_inches=\"tight\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "%matplotlib agg\n",
    "# multiple saliency maps for each example\n",
    "for (image, label), (original, _) in zip(dataset_loader, originals_loader):\n",
    "    fig, _ = util.visualize_cascading_randomization2(\n",
    "        resnet,\n",
    "        module_paths,\n",
    "        [(Saliency, False), (Saliency, True), (InputXGradient, False), (InputXGradient, True), (GuidedBackprop, False), (IntegratedGradients, False)],\n",
    "        ['Gradient', 'SmoothGrad', 'Gradient ⊙ Input', 'Gradient ⊙ Input-SG', 'Guided Back-propagation', 'Integrated Gradients'],\n",
    "        (image, label),\n",
    "        original,\n",
    "        viz_method=\"heat_map\"\n",
    "    )\n",
    "    fig.savefig(\"figures/resnet-imagenet/cascrand.png\", bbox_inches=\"tight\")\n",
    "    break"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/konrad/miniconda3/envs/sanity_checks_pytorch/lib/python3.9/site-packages/captum/attr/_core/guided_backprop_deconvnet.py:60: UserWarning: Setting backward hooks on ReLU activations.The hooks will be removed after the attribution is finished\n",
      "  warnings.warn(\n",
      "/home/konrad/miniconda3/envs/sanity_checks_pytorch/lib/python3.9/site-packages/torch/nn/modules/module.py:974: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/konrad/miniconda3/envs/sanity_checks_pytorch/lib/python3.9/site-packages/captum/attr/_utils/visualization.py:44: UserWarning: Attempting to normalize by value approximately 0, visualized resultsmay be misleading. This likely means that attribution values are allclose to 0.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n",
      "Working on Saliency\n",
      "Working on Saliency\n",
      "Working on InputXGradient\n",
      "Working on InputXGradient\n",
      "Working on GuidedBackprop\n",
      "Working on IntegratedGradients\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "dic = util.ssim_saliency_comparison(\n",
    "    resnet,\n",
    "    module_paths,\n",
    "        [(Saliency, False), (Saliency, True), (InputXGradient, False), (InputXGradient, True), (GuidedBackprop, False), (IntegratedGradients, False)],\n",
    "        ['Gradient', 'SmoothGrad', 'Gradient ⊙ Input', 'Gradient ⊙ Input-SG', 'Guided Back-propagation', 'Integrated Gradients'], # integrated gradients takes a really long time\n",
    "    dataset_loader\n",
    "    )"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/konrad/miniconda3/envs/sanity_checks_pytorch/lib/python3.9/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/home/konrad/Documents/Uni/DL/sanity_checks_pytorch/src/util.py:234: UserWarning: DEPRECATED: skimage.measure.compare_ssim has been moved to skimage.metrics.structural_similarity. It will be removed from skimage.measure in version 0.18.\n",
      "  ssim_sum += compare_ssim(original_explanations[(img_id, sal_id)], attribution, multichannel=True, gaussian_weights=True) # calculate ssim score with original attribution and add to sum\n"
     ]
    }
   ],
   "metadata": {
    "scrolled": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "dic"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'Gradient': {'fc': 0.6988636805595543,\n",
       "  'layer4_1': 0.6243430175047996,\n",
       "  'layer4_0': 0.5763960636408851,\n",
       "  'layer3_1': 0.5236429602603492,\n",
       "  'layer3_0': 0.5222669677398154,\n",
       "  'layer2_1': 0.4995225375566238,\n",
       "  'layer2_0': 0.48712593568497986,\n",
       "  'layer1_1': 0.3663305949713293,\n",
       "  'layer1_0': 0.31341853440773104,\n",
       "  'bn1': 0.2888173423816648,\n",
       "  'conv1': 0.38512609278961},\n",
       " 'SmoothGrad': {'fc': 0.7888577028510921,\n",
       "  'layer4_1': 0.6293241249616182,\n",
       "  'layer4_0': 0.6220412260185424,\n",
       "  'layer3_1': 0.6179409972797342,\n",
       "  'layer3_0': 0.5328704413192613,\n",
       "  'layer2_1': 0.5115607579962979,\n",
       "  'layer2_0': 0.5808584332516571,\n",
       "  'layer1_1': 0.5428970255790462,\n",
       "  'layer1_0': 0.5478941158185873,\n",
       "  'bn1': 0.5259110887664706,\n",
       "  'conv1': 0.4466546961275455},\n",
       " 'Gradient ⊙ Input': {'fc': 0.7876274863806909,\n",
       "  'layer4_1': 0.8001470084497238,\n",
       "  'layer4_0': 0.8047597977099563,\n",
       "  'layer3_1': 0.800145250448771,\n",
       "  'layer3_0': 0.7734568350632269,\n",
       "  'layer2_1': 0.7612311797559872,\n",
       "  'layer2_0': 0.7933035302104068,\n",
       "  'layer1_1': 0.7189298704337896,\n",
       "  'layer1_0': 0.6902145645969961,\n",
       "  'bn1': 0.6861461956334203,\n",
       "  'conv1': 0.755438225640406},\n",
       " 'Gradient ⊙ Input-SG': {'fc': 0.7633768701545518,\n",
       "  'layer4_1': 0.7752158849275694,\n",
       "  'layer4_0': 0.7520870810845914,\n",
       "  'layer3_1': 0.7402119892237706,\n",
       "  'layer3_0': 0.7328162356004219,\n",
       "  'layer2_1': 0.733521602563209,\n",
       "  'layer2_0': 0.7274481478093155,\n",
       "  'layer1_1': 0.723474404434265,\n",
       "  'layer1_0': 0.7410304319384976,\n",
       "  'bn1': 0.74150307687281,\n",
       "  'conv1': 0.7946856857873915},\n",
       " 'Guided Back-propagation': {'fc': 0.9948078951845065,\n",
       "  'layer4_1': 0.9867610393296287,\n",
       "  'layer4_0': 0.9853641054241443,\n",
       "  'layer3_1': 0.9596002642276463,\n",
       "  'layer3_0': 0.918529293694905,\n",
       "  'layer2_1': 0.9279312302420916,\n",
       "  'layer2_0': 0.9218016014913882,\n",
       "  'layer1_1': 0.9066467498779913,\n",
       "  'layer1_0': 0.8855035326867011,\n",
       "  'bn1': 0.8820332662265591,\n",
       "  'conv1': 0.8317211561652733},\n",
       " 'Integrated Gradients': {'fc': 0.7524378764080709,\n",
       "  'layer4_1': 0.7541264946251148,\n",
       "  'layer4_0': 0.7430216269715922,\n",
       "  'layer3_1': 0.778270509274771,\n",
       "  'layer3_0': 0.7360967333331041,\n",
       "  'layer2_1': 0.7335062157275127,\n",
       "  'layer2_0': 0.7388866962252936,\n",
       "  'layer1_1': 0.701468907977486,\n",
       "  'layer1_0': 0.6788772319124164,\n",
       "  'bn1': 0.6787520862602885,\n",
       "  'conv1': 0.7502564803336018}}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "%matplotlib agg\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "ax = fig.subplots()\n",
    "#plot similarities\n",
    "for key, value in dic.items():\n",
    "    ax.plot(\n",
    "        ['original'] + list(value.keys()), [1] + list(value.values()),\n",
    "        label=key,\n",
    "        linestyle='dashed', linewidth=3.5, marker='o', markersize=10\n",
    "    )\n",
    "\n",
    "ax.grid(True)\n",
    "ax.legend()\n",
    "fig.savefig(\"figures/resnet-imagenet/ssim_cascrand.png\", bbox_inches=\"tight\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "image = dic[(340, 0)]\n",
    "plt.figure()\n",
    "plt.axis('off')\n",
    "plt.imshow(image, cmap=\"Reds\")\n",
    "print(image)\n",
    "print(image.shape)\n",
    "print(len(dic))\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "(340, 0)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-c1b9bb182121>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m340\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Reds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: (340, 0)"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('sanity_checks_pytorch': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "interpreter": {
   "hash": "11fbf37fbd24df55005c3b93a6722ff80f8e94e0a7328b0b9ff32e8c2e8e8123"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}