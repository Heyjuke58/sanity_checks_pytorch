{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cc2b2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# Hyperparams\n",
    "batch_size = 50\n",
    "loss_func = F.cross_entropy\n",
    "epochs = 50\n",
    "\n",
    "# GPU/CPU\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "\n",
    "# Datasets\n",
    "train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "val_kwargs = {'batch_size': batch_size}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True}\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    val_kwargs.update(cuda_kwargs)\n",
    "\n",
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "dataset1, dataset2 = torch.utils.data.random_split(dataset, [55000, 5000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset1, **train_kwargs)\n",
    "val_loader = torch.utils.data.DataLoader(dataset2, **val_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53da27c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=3136, out_features=1024, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# model\n",
    "    \n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 32, 5, 1, padding=(2, 2)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Conv2d(32, 64, 5, 1, padding=(2, 2)),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(7 * 7 * 64, 1024),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(1024, 10)\n",
    ")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50dc521c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe7338c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/konrad/miniconda3/envs/sanity_checks_pytorch/lib/python3.9/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /opt/conda/conda-bld/pytorch_1623448255797/work/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss acc 0 epoch(s): 0.9765999913215637\n",
      "Val Loss acc 1 epoch(s): 0.9852001667022705\n",
      "Val Loss acc 2 epoch(s): 0.9852003455162048\n",
      "Val Loss acc 3 epoch(s): 0.9904001355171204\n",
      "Val Loss acc 4 epoch(s): 0.987200140953064\n",
      "Val Loss acc 5 epoch(s): 0.988800048828125\n",
      "Val Loss acc 6 epoch(s): 0.9898000359535217\n",
      "Val Loss acc 7 epoch(s): 0.9912002086639404\n",
      "Val Loss acc 8 epoch(s): 0.9894003868103027\n",
      "Val Loss acc 9 epoch(s): 0.99180006980896\n",
      "Val Loss acc 10 epoch(s): 0.9916000962257385\n",
      "Val Loss acc 11 epoch(s): 0.9902000427246094\n",
      "Val Loss acc 12 epoch(s): 0.9932000637054443\n",
      "Val Loss acc 13 epoch(s): 0.9924002885818481\n",
      "Val Loss acc 14 epoch(s): 0.9930002093315125\n",
      "Val Loss acc 15 epoch(s): 0.9888002276420593\n",
      "Val Loss acc 16 epoch(s): 0.9913999438285828\n",
      "Val Loss acc 17 epoch(s): 0.9904001355171204\n",
      "Val Loss acc 18 epoch(s): 0.9926002025604248\n",
      "Val Loss acc 19 epoch(s): 0.9924001693725586\n",
      "Val Loss acc 20 epoch(s): 0.9924001693725586\n",
      "Val Loss acc 21 epoch(s): 0.9924001693725586\n",
      "Val Loss acc 22 epoch(s): 0.9924002885818481\n",
      "Val Loss acc 23 epoch(s): 0.9916002154350281\n",
      "Val Loss acc 24 epoch(s): 0.9922000765800476\n",
      "Val Loss acc 25 epoch(s): 0.9928001761436462\n",
      "Val Loss acc 26 epoch(s): 0.990200400352478\n",
      "Val Loss acc 27 epoch(s): 0.9934000968933105\n",
      "Val Loss acc 28 epoch(s): 0.9912000894546509\n",
      "Val Loss acc 29 epoch(s): 0.9928001761436462\n",
      "Val Loss acc 30 epoch(s): 0.9932001233100891\n",
      "Val Loss acc 31 epoch(s): 0.9942001700401306\n",
      "Val Loss acc 32 epoch(s): 0.9940001964569092\n",
      "Val Loss acc 33 epoch(s): 0.9930001497268677\n",
      "Val Loss acc 34 epoch(s): 0.9940000772476196\n",
      "Val Loss acc 35 epoch(s): 0.9940000772476196\n",
      "Val Loss acc 36 epoch(s): 0.99260014295578\n",
      "Val Loss acc 37 epoch(s): 0.9932001829147339\n",
      "Val Loss acc 38 epoch(s): 0.9934001564979553\n",
      "Val Loss acc 39 epoch(s): 0.9932001233100891\n",
      "Val Loss acc 40 epoch(s): 0.9936001896858215\n",
      "Val Loss acc 41 epoch(s): 0.9914001226425171\n",
      "Val Loss acc 42 epoch(s): 0.9914000630378723\n",
      "Val Loss acc 43 epoch(s): 0.99260014295578\n",
      "Val Loss acc 44 epoch(s): 0.9934000968933105\n",
      "Val Loss acc 45 epoch(s): 0.9912000894546509\n",
      "Val Loss acc 46 epoch(s): 0.9938002824783325\n",
      "Val Loss acc 47 epoch(s): 0.9936001300811768\n",
      "Val Loss acc 48 epoch(s): 0.9934001564979553\n",
      "Val Loss acc 49 epoch(s): 0.9934001564979553\n"
     ]
    }
   ],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()\n",
    "\n",
    "# Training\n",
    "best_val_acc = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_func(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_acc = 0\n",
    "        for batch_idx, (data, target) in enumerate(val_loader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            val_acc += accuracy(output, target)\n",
    "    \n",
    "        val_acc = val_acc / len(val_loader)\n",
    "\n",
    "        print(f'Val Loss acc {epoch} epoch(s): {val_acc}')\n",
    "\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model, 'cnn_mnist')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
